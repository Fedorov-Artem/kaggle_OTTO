{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc969a74",
   "metadata": {
    "papermill": {
     "duration": 0.00616,
     "end_time": "2023-03-23T12:48:12.834714",
     "exception": false,
     "start_time": "2023-03-23T12:48:12.828554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OTTO common functions for feature engineering\n",
    "This notebook contains functions, used for feature engineering in the OTTO project.\n",
    "Three feature engineering notebooks of the project have a huge number of mostly the same functions, and copying the functions between notebooks made them too long and hard to manage. So, I had to move functions, common among those notebooks, to a special shared notebook.\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c78ca5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:12.847720Z",
     "iopub.status.busy": "2023-03-23T12:48:12.847162Z",
     "iopub.status.idle": "2023-03-23T12:48:12.873624Z",
     "shell.execute_reply": "2023-03-23T12:48:12.872380Z"
    },
    "papermill": {
     "duration": 0.036706,
     "end_time": "2023-03-23T12:48:12.876647",
     "exception": false,
     "start_time": "2023-03-23T12:48:12.839941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "     \n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "# functions and classes common for several notebooks of current project\n",
    "import otto_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0ac505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:12.888985Z",
     "iopub.status.busy": "2023-03-23T12:48:12.888219Z",
     "iopub.status.idle": "2023-03-23T12:48:25.529531Z",
     "shell.execute_reply": "2023-03-23T12:48:25.528140Z"
    },
    "papermill": {
     "duration": 12.650866,
     "end_time": "2023-03-23T12:48:25.532665",
     "exception": false,
     "start_time": "2023-03-23T12:48:12.881799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /opt/conda/lib/python3.7/site-packages (0.16.8)\r\n",
      "Requirement already satisfied: typing_extensions>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from polars) (4.4.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Use polars to speed up the most time-consuming operations.\n",
    "!pip install polars\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9092ccf",
   "metadata": {
    "papermill": {
     "duration": 0.005309,
     "end_time": "2023-03-23T12:48:25.543653",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.538344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## General functions for feature engineering\n",
    "These are functions, used in more than one of feature engineering notebooks - notebooks, that import already generated candidates and add some information so that the ranker model could rank the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5d695a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.556934Z",
     "iopub.status.busy": "2023-03-23T12:48:25.556460Z",
     "iopub.status.idle": "2023-03-23T12:48:25.567066Z",
     "shell.execute_reply": "2023-03-23T12:48:25.565873Z"
    },
    "papermill": {
     "duration": 0.020403,
     "end_time": "2023-03-23T12:48:25.569544",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.549141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the candidates, reduce datatypes and in case of cross-validation dataset also filter out sessions without positive candidates. \n",
    "def cand_read_and_reduce(df, target_string, is_cv):\n",
    "    target_predictions = target_string + '_predictions'\n",
    "    if is_cv:\n",
    "        ground_truth = target_string + 's'\n",
    "        df = df.loc[df['pred_true'] > 0]\n",
    "        df = df[['session', target_predictions, ground_truth]]\n",
    "    else:\n",
    "        df = df[['session', target_predictions]]\n",
    "    df['session'] = df['session'].astype(np.int32)\n",
    "    df = df.explode(target_predictions).reset_index(drop=True)\n",
    "    df[target_predictions] = df[target_predictions].astype(np.int32)\n",
    "    gc.collect()\n",
    "    if is_cv:\n",
    "        if target_string == 'click':\n",
    "            df['target'] = 0\n",
    "            df.loc[df['click_predictions'] == df['clicks'], 'target'] = 1\n",
    "        else:\n",
    "            df['target'] = df.apply(lambda x: x[target_predictions] in x[ground_truth], axis=1)\n",
    "        df['target'] = df['target'].astype(bool)\n",
    "        del df[ground_truth]\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290ce4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.582388Z",
     "iopub.status.busy": "2023-03-23T12:48:25.581973Z",
     "iopub.status.idle": "2023-03-23T12:48:25.594305Z",
     "shell.execute_reply": "2023-03-23T12:48:25.592835Z"
    },
    "papermill": {
     "duration": 0.021851,
     "end_time": "2023-03-23T12:48:25.596845",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.574994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For candidates present in session history, add a few features, including:\n",
    "# A. position in session history ('n')\n",
    "# B. time in seconds from last mention in session history to last known event ('time_delta')\n",
    "# C. number of interactions with the item ('count_views')\n",
    "# For candidates, that do not come from session history, the functions fills in some default values.\n",
    "def add_history_aid_features(input_path, df_candidate, prediction_col):\n",
    "    df_test = pd.read_parquet(input_path)\n",
    "    df_test = df_test.sort_values(['session','ts'],ascending=[True,False])\n",
    "    df_test['n'] = df_test.groupby('session').cumcount().astype(np.int16)\n",
    "    df_test['time_delta'] = df_test.groupby('session')['ts'].transform(np.max).astype(np.int32)\n",
    "    df_test['time_delta'] = df_test['time_delta'] - df_test['ts']\n",
    "    df_test = df_test.groupby(['session', 'aid']).agg({'n': np.min, 'time_delta': np.min, 'ts': 'nunique'})\n",
    "    df_test = df_test.rename(columns={'ts':'count_views'}).reset_index()\n",
    "    df_candidate = pd.merge(df_candidate, df_test,\n",
    "                            how='left', left_on=['session', prediction_col],right_on=['session', 'aid'])\n",
    "    del df_candidate['aid']\n",
    "    gc.collect()\n",
    "    df_candidate['n'] = df_candidate['n'].fillna(10000).astype(np.int16)\n",
    "    df_candidate['time_delta'] = df_candidate['time_delta'].fillna(1000000).astype(np.int32)\n",
    "    df_candidate['count_views'] = df_candidate['count_views'].fillna(0).clip(0,125).astype(np.int8)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985a1500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.610075Z",
     "iopub.status.busy": "2023-03-23T12:48:25.609666Z",
     "iopub.status.idle": "2023-03-23T12:48:25.621663Z",
     "shell.execute_reply": "2023-03-23T12:48:25.620410Z"
    },
    "papermill": {
     "duration": 0.022148,
     "end_time": "2023-03-23T12:48:25.624592",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.602444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adds columns, including last aid, aid before last, day of week for the last event and time between last two events.\n",
    "# Time between last two aids in session is used as a feature in all the models, rest of columns are used to engineer other features.\n",
    "\n",
    "def add_history_agg_features(input_path, df_candidate, remove_first_second=True):\n",
    "    df_test = pd.read_parquet(input_path)\n",
    "    df_test = df_test.sort_values(['session','ts'],ascending=[True,False])\n",
    "    df_test['n'] = df_test.groupby('session').cumcount().astype(np.int16)\n",
    "    df_test_first = df_test.loc[df_test['n'] == 0].drop('n',axis=1)\n",
    "    df_test_first = df_test_first.add_prefix('first_')\n",
    "    df_test_second = df_test.loc[df_test['n'] == 1].drop('n',axis=1)\n",
    "    df_test_second = df_test_second.add_prefix('second_')\n",
    "    df_last_two = pd.merge(df_test_first, df_test_second,\n",
    "                           left_on='first_session', right_on='second_session', how='left')\n",
    "    df_last_two['ts_diff'] = df_last_two['first_ts'] - df_last_two['second_ts']\n",
    "    df_last_two = df_last_two[['first_session', 'first_aid', 'first_ts', 'second_aid', 'ts_diff']]\n",
    "    df_last_two['second_aid'] = df_last_two['second_aid'].fillna(-1).astype(np.int32)\n",
    "    df_last_two['ts_diff'] = df_last_two['ts_diff'].fillna(1000000).astype(np.int32)\n",
    "    df_last_two = df_last_two.rename(columns={'first_session' : 'session'})\n",
    "    df_last_two = otto_common.add_datetime(df_last_two, 'first_ts')\n",
    "    df_last_two['day_of_week'] = df_last_two['time'].dt.dayofweek.astype(np.int8)\n",
    "    df_last_two = df_last_two[['session', 'first_aid', 'second_aid', 'ts_diff', 'day_of_week']]\n",
    "    df_candidate = pd.merge(df_candidate, df_last_two, how='left', on='session')\n",
    "    if remove_first_second:\n",
    "        del df_candidate['first_aid'], df_candidate['second_aid']\n",
    "        gc.collect()\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4e3c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.638292Z",
     "iopub.status.busy": "2023-03-23T12:48:25.637876Z",
     "iopub.status.idle": "2023-03-23T12:48:25.648234Z",
     "shell.execute_reply": "2023-03-23T12:48:25.646988Z"
    },
    "papermill": {
     "duration": 0.020404,
     "end_time": "2023-03-23T12:48:25.650988",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.630584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates time from a moment user interacted with aid to the next event for candidates, present in session history.\n",
    "# Those values are clipped to 180 seconds and are then summed up if a user interacted with aid more than once.\n",
    "def add_time_viewed(input_path, df_candidate, prediction_col):\n",
    "    df_test = pd.read_parquet(input_path)\n",
    "    df_test['n'] = df_test.groupby('session').cumcount().astype(np.int16)\n",
    "    del df_test['type']\n",
    "    gc.collect()\n",
    "    df_test_plus_1 = df_test.copy()\n",
    "    df_test_plus_1['n'] = df_test_plus_1['n'] - 1\n",
    "    df_test = df_test.merge(df_test_plus_1, how='inner', on=['session', 'n'])\n",
    "    del df_test_plus_1\n",
    "    gc.collect()\n",
    "    df_test['time_viewed'] = df_test['ts_y'] - df_test['ts_x']\n",
    "    df_test = df_test[['session', 'aid_x', 'time_viewed']]\n",
    "    df_test['time_viewed'] = df_test['time_viewed'].clip(0,180)\n",
    "    df_test = df_test.groupby(['session', 'aid_x']).agg({'time_viewed':'sum'})\n",
    "    df_test = df_test.reset_index()\n",
    "    df_candidate = df_candidate.merge(df_test, how='left',\n",
    "                        left_on=['session',prediction_col], right_on=['session','aid_x'])\n",
    "    df_candidate['time_viewed'] = df_candidate['time_viewed'].fillna(0).astype(np.int16)\n",
    "    df_candidate = df_candidate.drop('aid_x', axis=1)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db5d7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.664479Z",
     "iopub.status.busy": "2023-03-23T12:48:25.664044Z",
     "iopub.status.idle": "2023-03-23T12:48:25.674799Z",
     "shell.execute_reply": "2023-03-23T12:48:25.673478Z"
    },
    "papermill": {
     "duration": 0.020855,
     "end_time": "2023-03-23T12:48:25.677431",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.656576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adds values for averaged daily clicks/carts/orders of every aid.\n",
    "# Those values are pre-calculated in another notebook (counts_for_clicks or counts_for_buys).\n",
    "def add_daily_averages(daily_counts_before, daily_counts_during, df_candidate, prediction_col):\n",
    "    df_before = pd.read_parquet(daily_counts_before)\n",
    "    df_before = df_before.loc[df_before['day_of_week'] == 6]\n",
    "    df_before['day_of_week'] = 0\n",
    "    df_candidate = pd.merge(df_candidate, df_before, how = 'left', left_on = [prediction_col, 'day_of_week'],\n",
    "                   right_on = ['aid', 'day_of_week'])\n",
    "    df_candidate['daily_aid_count'] = df_candidate['aid_count']\n",
    "    df_candidate = df_candidate.drop(['aid', 'aid_count'], axis=1)\n",
    "    del df_before\n",
    "    gc.collect()\n",
    "    df_during = pd.read_parquet(daily_counts_during)\n",
    "    for i in range(6):\n",
    "        df_i = df_during.loc[df_during['day_of_week'] == i].copy()\n",
    "        df_i['day_of_week'] = df_i['day_of_week'] + 1\n",
    "        df_candidate = pd.merge(df_candidate, df_i, how = 'left', left_on = [prediction_col, 'day_of_week'],\n",
    "                           right_on = ['aid', 'day_of_week'])\n",
    "        df_candidate['daily_aid_count'] = df_candidate['daily_aid_count'].fillna(df_candidate['aid_count'])\n",
    "        df_candidate = df_candidate.drop(['aid', 'aid_count'], axis=1)\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    df_candidate['daily_aid_count'] = df_candidate['daily_aid_count'].fillna(0).astype(np.float32)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b73b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.690995Z",
     "iopub.status.busy": "2023-03-23T12:48:25.690510Z",
     "iopub.status.idle": "2023-03-23T12:48:25.703096Z",
     "shell.execute_reply": "2023-03-23T12:48:25.701661Z"
    },
    "papermill": {
     "duration": 0.022695,
     "end_time": "2023-03-23T12:48:25.705730",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.683035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates average weekly clicks/carts/orders by summing up the pre-calculated daily clicks/carts/orders.\n",
    "# Those values are pre-calculated in another notebook (counts_for_clicks or counts_for_buys).\n",
    "def add_weekly_averages(daily_counts_before, daily_counts_during, df_candidate, prediction_col):\n",
    "    df_before = pd.read_parquet(daily_counts_before)\n",
    "    df_during = pd.read_parquet(daily_counts_during)\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            k = i + j\n",
    "            if k < 7:\n",
    "                df_j = df_before.loc[df_before['day_of_week'] == k]\n",
    "            else:\n",
    "                df_j = df_during.loc[df_during['day_of_week'] == k-7]\n",
    "            df_j = df_j.drop(['day_of_week'], axis=1)\n",
    "            if j == 0:\n",
    "                df_i = df_j\n",
    "                df_i['aid_count_total'] = df_i['aid_count']\n",
    "            else:\n",
    "                df_i = pd.merge(df_i, df_j, how='outer', on='aid')\n",
    "                df_i['aid_count'] = df_i['aid_count'].fillna(0)\n",
    "                df_i['aid_count_total'] = df_i['aid_count_total'].fillna(0)\n",
    "                df_i['aid_count_total'] = df_i['aid_count_total'] + df_i['aid_count']\n",
    "            df_i = df_i.drop(['aid_count'], axis=1)\n",
    "        df_i['day_of_week'] = i\n",
    "        df_candidate = pd.merge(df_candidate, df_i, how = 'left', left_on = [prediction_col, 'day_of_week'],\n",
    "                           right_on = ['aid', 'day_of_week'])\n",
    "        if i == 0:\n",
    "            df_candidate['aid_count_weekly'] = df_candidate['aid_count_total']\n",
    "        else:\n",
    "            df_candidate['aid_count_weekly'] = df_candidate['aid_count_weekly'].fillna(df_candidate['aid_count_total'])\n",
    "        df_candidate = df_candidate.drop(['aid', 'aid_count_total'], axis=1)\n",
    "    df_candidate['aid_count_weekly'] = df_candidate['aid_count_weekly'].fillna(0).astype(np.float32)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b6ae89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.719013Z",
     "iopub.status.busy": "2023-03-23T12:48:25.718588Z",
     "iopub.status.idle": "2023-03-23T12:48:25.725468Z",
     "shell.execute_reply": "2023-03-23T12:48:25.724098Z"
    },
    "papermill": {
     "duration": 0.016691,
     "end_time": "2023-03-23T12:48:25.728069",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.711378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data for a median time aid was viewed (means median time from an event with aid to any next event).\n",
    "# Those median times are calculated in create_counts_for_clicks notebook.\n",
    "def add_median_time_viewed(time_viewed_path, df_candidate, prediction_col):\n",
    "    df_time_viewed = pd.read_parquet(time_viewed_path)\n",
    "    df_candidate = pd.merge(df_candidate, df_time_viewed, how='left', left_on=prediction_col, right_on='aid_x')\n",
    "    df_candidate['time_viewed_clipped'] = df_candidate['time_viewed_clipped'].fillna(60)\n",
    "    df_candidate = df_candidate.drop('aid_x', axis=1)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d87440c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.741836Z",
     "iopub.status.busy": "2023-03-23T12:48:25.741426Z",
     "iopub.status.idle": "2023-03-23T12:48:25.748932Z",
     "shell.execute_reply": "2023-03-23T12:48:25.747604Z"
    },
    "papermill": {
     "duration": 0.017557,
     "end_time": "2023-03-23T12:48:25.751554",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.733997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates the most actual event type for aids present in session history.\n",
    "# If aid was either added to cart or ordered, the function selects the last of these event types.\n",
    "# Click event type is only selected for aids that were clicked, but never carted or ordered.\n",
    "def add_type_last(input_path, df_candidate, prediction_col):\n",
    "    df_sessions = pd.read_parquet(input_path)\n",
    "    df_sessions = df_sessions.loc[df_sessions['type'] > 0]\n",
    "    df_sessions = df_sessions.groupby(['session', 'aid']).agg({'type':'last'})\n",
    "    df_sessions = df_sessions.rename(columns={'type':'type_last'})\n",
    "    df_candidate = pd.merge(df_candidate, df_sessions, how='left', left_on=['session',prediction_col], right_index=True)\n",
    "    df_candidate['type_last'] = df_candidate['type_last'].fillna(0).astype(np.int8)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cacd21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.766115Z",
     "iopub.status.busy": "2023-03-23T12:48:25.765228Z",
     "iopub.status.idle": "2023-03-23T12:48:25.774062Z",
     "shell.execute_reply": "2023-03-23T12:48:25.772631Z"
    },
    "papermill": {
     "duration": 0.019334,
     "end_time": "2023-03-23T12:48:25.776765",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.757431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Total number of events in last 3 hours of the session.\n",
    "def count_events_3hours(input_path, df_candidate):\n",
    "    df_sessions = pd.read_parquet(input_path)\n",
    "    df_sessions['time_delta'] = df_sessions.groupby('session')['ts'].transform(np.max).astype(np.int32)\n",
    "    df_sessions['time_delta'] = df_sessions['time_delta'] - df_sessions['ts']\n",
    "    df_sessions = df_sessions.loc[df_sessions['time_delta'] < 3*60*60]\n",
    "    df_sessions = df_sessions.groupby('session').size()\n",
    "    df_sessions.name = 'events_last_3hours'\n",
    "    df_candidate = pd.merge(df_candidate, df_sessions, how='left', left_on= 'session', right_index=True)\n",
    "    df_candidate['events_last_3hours'] = df_candidate['events_last_3hours'].clip(0,125).astype(np.int8)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec8447d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.791557Z",
     "iopub.status.busy": "2023-03-23T12:48:25.790812Z",
     "iopub.status.idle": "2023-03-23T12:48:25.796437Z",
     "shell.execute_reply": "2023-03-23T12:48:25.795112Z"
    },
    "papermill": {
     "duration": 0.016642,
     "end_time": "2023-03-23T12:48:25.799383",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.782741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# W2vec mean similarity between last aid and previous 4 aids before the last one.\n",
    "# Loads pre-calculated in create_counts_for_buys notebook similarities.\n",
    "def add_history_similarity(history_path, df_candidate):\n",
    "    df_history = pd.read_parquet(history_path)\n",
    "    df_candidate = pd.merge(df_candidate, df_history, how='left', on='session')\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23f6c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.813323Z",
     "iopub.status.busy": "2023-03-23T12:48:25.812888Z",
     "iopub.status.idle": "2023-03-23T12:48:25.820464Z",
     "shell.execute_reply": "2023-03-23T12:48:25.818974Z"
    },
    "papermill": {
     "duration": 0.018003,
     "end_time": "2023-03-23T12:48:25.823275",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.805272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Total amount of buys in session.\n",
    "def add_total_buys_in_session(trunked_sessions, df_candidate):\n",
    "    df_sessions = pd.read_parquet(trunked_sessions)\n",
    "    df_sessions = df_sessions.loc[df_sessions['type'] > 0]\n",
    "    df_sessions = df_sessions.groupby('session').size()\n",
    "    gc.collect()\n",
    "    df_sessions.name = \"buys_this_session\"\n",
    "    df_candidate = pd.merge(df_candidate, df_sessions, how='left',\n",
    "                            left_on='session', right_index=True)\n",
    "    df_candidate['buys_this_session'] = df_candidate['buys_this_session'].fillna(0).astype(np.int16)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d68de76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.837246Z",
     "iopub.status.busy": "2023-03-23T12:48:25.836845Z",
     "iopub.status.idle": "2023-03-23T12:48:25.844872Z",
     "shell.execute_reply": "2023-03-23T12:48:25.843599Z"
    },
    "papermill": {
     "duration": 0.018088,
     "end_time": "2023-03-23T12:48:25.847414",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.829326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time in seconds from first to last event.\n",
    "def add_session_time(input_path, df_candidate):\n",
    "    df_sessions = pd.read_parquet(input_path)\n",
    "    df_sessions = df_sessions.groupby('session').agg(ts_min=('ts', np.min), ts_max=('ts', np.max))\n",
    "    df_sessions['session_time'] = df_sessions.ts_max - df_sessions.ts_min\n",
    "    df_sessions['session_time'] = df_sessions['session_time'].astype(np.int32)\n",
    "    df_sessions = df_sessions.drop(['ts_min', 'ts_max'], axis=1)\n",
    "    df_candidate = pd.merge(df_candidate, df_sessions, how='left', left_on= 'session', right_index=True)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1cbc75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.862068Z",
     "iopub.status.busy": "2023-03-23T12:48:25.861635Z",
     "iopub.status.idle": "2023-03-23T12:48:25.868025Z",
     "shell.execute_reply": "2023-03-23T12:48:25.867042Z"
    },
    "papermill": {
     "duration": 0.016515,
     "end_time": "2023-03-23T12:48:25.870364",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.853849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average clicks on each aid before it is bought for the first time.\n",
    "# Loads values, pre-calculated in create_counts_for_buys notebook.\n",
    "def add_clicks_before_buy(clicks_before_buy_path, df_candidate, prediction_col):\n",
    "    df_clicks = pd.read_parquet(clicks_before_buy_path)\n",
    "    df_candidate = pd.merge(df_candidate, df_clicks, how='left', left_on=prediction_col, right_on='aid')\n",
    "    df_candidate['clicks_before_buy'] = df_candidate['clicks_before_buy'].fillna(2).astype(np.float32)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce75c361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.884223Z",
     "iopub.status.busy": "2023-03-23T12:48:25.883814Z",
     "iopub.status.idle": "2023-03-23T12:48:25.893165Z",
     "shell.execute_reply": "2023-03-23T12:48:25.891608Z"
    },
    "papermill": {
     "duration": 0.019696,
     "end_time": "2023-03-23T12:48:25.896083",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.876387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load daily averages for the day of last known event in session.\n",
    "def add_daily_averages_same_day(daily_counts_during, df_candidate, prediction_col):\n",
    "    df_during = pd.read_parquet(daily_counts_during)\n",
    "    df_candidate['same_day_aid_count'] = np.NaN\n",
    "    for i in range(7):\n",
    "        df_i = df_during.loc[df_during['day_of_week'] == i]\n",
    "        df_candidate = pd.merge(df_candidate, df_i, how = 'left', left_on = [prediction_col, 'day_of_week'],\n",
    "                           right_on = ['aid', 'day_of_week'])\n",
    "        df_candidate['same_day_aid_count'] = df_candidate['same_day_aid_count'].fillna(df_candidate['aid_count'])\n",
    "        df_candidate = df_candidate.drop(['aid', 'aid_count'], axis=1)\n",
    "        del df_i\n",
    "        gc.collect()\n",
    "    df_candidate['same_day_aid_count'] = df_candidate['same_day_aid_count'].fillna(0).astype(np.float32)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbcea55",
   "metadata": {
    "papermill": {
     "duration": 0.005705,
     "end_time": "2023-03-23T12:48:25.907913",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.902208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions to build features from co-visitation matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f8065dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.922346Z",
     "iopub.status.busy": "2023-03-23T12:48:25.921955Z",
     "iopub.status.idle": "2023-03-23T12:48:25.929686Z",
     "shell.execute_reply": "2023-03-23T12:48:25.928285Z"
    },
    "papermill": {
     "duration": 0.018222,
     "end_time": "2023-03-23T12:48:25.932093",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.913871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function normalizes matrix before calculating features.\n",
    "# Normalize here means to divide all weights by sum of weights per aid_x.\n",
    "# Some co-validation matrixes are normalized before calculating features, while others are not.\n",
    "def normalize_matrice(df):\n",
    "    print('start normalizing')\n",
    "    df = df.select([\n",
    "        pl.all(),\n",
    "        pl.col(\"wgt\").sum().over(\"aid_x\").alias(\"wgt_sum\")\n",
    "    ])\n",
    "    df = df.with_column((100 * pl.col(\"wgt\") / pl.col(\"wgt_sum\"))\n",
    "                        .alias(\"wgt\").cast(pl.Float32))\n",
    "    df = df.drop('wgt_sum')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fcda95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.946729Z",
     "iopub.status.busy": "2023-03-23T12:48:25.946271Z",
     "iopub.status.idle": "2023-03-23T12:48:25.960431Z",
     "shell.execute_reply": "2023-03-23T12:48:25.959538Z"
    },
    "papermill": {
     "duration": 0.024804,
     "end_time": "2023-03-23T12:48:25.962995",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.938191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function is used to build features based on co-visitation matrixes. \n",
    "# It sums weights for n_max last aids in each session (aid_x) and the candidate aid (aid_y).\n",
    "# This function is computationally heavy, but it builds a number of features with \n",
    "# very high feature importance. I had to rewrite it using polars, to speed up feature generation.\n",
    "# Same function on pandas runs too slow.\n",
    "\n",
    "def add_matrice_data_polars(df_test, count_matrice, df_candidate, col_name, n_max, prediction_col,\n",
    "                            normalize=False, divide=False):\n",
    "    df_matrice = pl.read_parquet(count_matrice)\n",
    "    df_matrice = df_matrice.unique(subset=['aid_x', 'aid_y'])\n",
    "    df_matrice = df_matrice.drop('__index_level_0__')\n",
    "    if normalize:\n",
    "        df_matrice = normalize_matrice(df_matrice)\n",
    "    print(col_name)\n",
    "    for i in range(n_max):\n",
    "        print(str(i))\n",
    "        df_test_i = df_test.filter(pl.col(\"n\") == i).drop('n')\n",
    "        df_candidate = df_candidate.join(df_test_i, on='session', how='left')\n",
    "        df_candidate = df_candidate.join(df_matrice, left_on=['aid', prediction_col], how='left',\n",
    "                                         right_on=['aid_x','aid_y'])\n",
    "        df_candidate = df_candidate.drop('aid')\n",
    "        gc.collect()\n",
    "        if i == 0:\n",
    "            df_candidate = df_candidate.with_column(pl.col(\"wgt\").fill_null(0).alias(col_name))\n",
    "        else:\n",
    "            if divide:\n",
    "                df_candidate = df_candidate.with_column((pl.col(\"wgt\").fill_null(0)/(i+1) + pl.col(col_name))\n",
    "                                                        .alias(col_name).cast(pl.Float32))\n",
    "            else:\n",
    "                df_candidate = df_candidate.with_column((pl.col(\"wgt\").fill_null(0) + pl.col(col_name))\n",
    "                                                    .alias(col_name).cast(pl.Float32))\n",
    "        df_candidate = df_candidate.drop('wgt')\n",
    "        gc.collect()\n",
    "    df_candidate = df_candidate.to_pandas()\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2182287c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T12:48:25.977260Z",
     "iopub.status.busy": "2023-03-23T12:48:25.976864Z",
     "iopub.status.idle": "2023-03-23T12:48:25.987491Z",
     "shell.execute_reply": "2023-03-23T12:48:25.986135Z"
    },
    "papermill": {
     "duration": 0.021158,
     "end_time": "2023-03-23T12:48:25.990404",
     "exception": false,
     "start_time": "2023-03-23T12:48:25.969246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# The same function on pandas, the one that works slowly.\\ndef add_matrice_data(df_test, count_matrice, df_candidate, n_max, col_name, time_frame, normalize=False):\\n    df_test = df_test.sort_values(['session','ts'],ascending=[True,False])\\n    df_test['n'] = df_test.groupby('session').cumcount().astype(np.int16)\\n    df_test['time_delta'] = df_test.groupby('session')['ts'].transform(np.max).astype(np.int32)\\n    df_test['time_delta'] = df_test['time_delta'] - df_test['ts']\\n    df_test = df_test.loc[df_test['time_delta'] < time_frame]\\n    gc.collect()\\n    df_test = df_test[['session', 'aid', 'n']]\\n    df_test = df_test.loc[df_test['n'] < n_max]\\n    gc.collect()\\n    df_matrice = pd.read_parquet(count_matrice)\\n    df_matrice = df_matrice.drop_duplicates(subset=['aid_x', 'aid_y'])\\n    df_matrice = df_matrice.set_index(['aid_x', 'aid_y'])\\n    print(col_name)\\n    for i in range(n_max):\\n        print(str(i))\\n        df_test_i = df_test.loc[df_test['n'] == i]\\n        df_test_i = df_test_i[['session', 'aid']]\\n        df_test_i = df_test_i.set_index('session')\\n        df_candidate = df_candidate.join(df_test_i, on='session', how='left')\\n        df_candidate = df_candidate.join(df_matrice, on=['aid', 'click_predictions'], how='left')\\n        df_candidate = df_candidate.drop('aid', axis=1)\\n        gc.collect()\\n        if i == 0:\\n            df_candidate[col_name] = df_candidate['wgt'].fillna(0)\\n            df_candidate[col_name] = df_candidate[col_name].astype(np.float32)\\n        else:\\n            if normalize:\\n                df_candidate[col_name] = df_candidate[col_name] + (df_candidate['wgt'].fillna(0))/(i+1)\\n            else:\\n                df_candidate[col_name] = df_candidate[col_name] + df_candidate['wgt'].fillna(0)\\n        df_candidate = df_candidate.drop(['wgt'], axis=1)\\n        gc.collect()\\n    return df_candidate\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# The same function on pandas, the one that works slowly.\n",
    "def add_matrice_data(df_test, count_matrice, df_candidate, n_max, col_name, time_frame, normalize=False):\n",
    "    df_test = df_test.sort_values(['session','ts'],ascending=[True,False])\n",
    "    df_test['n'] = df_test.groupby('session').cumcount().astype(np.int16)\n",
    "    df_test['time_delta'] = df_test.groupby('session')['ts'].transform(np.max).astype(np.int32)\n",
    "    df_test['time_delta'] = df_test['time_delta'] - df_test['ts']\n",
    "    df_test = df_test.loc[df_test['time_delta'] < time_frame]\n",
    "    gc.collect()\n",
    "    df_test = df_test[['session', 'aid', 'n']]\n",
    "    df_test = df_test.loc[df_test['n'] < n_max]\n",
    "    gc.collect()\n",
    "    df_matrice = pd.read_parquet(count_matrice)\n",
    "    df_matrice = df_matrice.drop_duplicates(subset=['aid_x', 'aid_y'])\n",
    "    df_matrice = df_matrice.set_index(['aid_x', 'aid_y'])\n",
    "    print(col_name)\n",
    "    for i in range(n_max):\n",
    "        print(str(i))\n",
    "        df_test_i = df_test.loc[df_test['n'] == i]\n",
    "        df_test_i = df_test_i[['session', 'aid']]\n",
    "        df_test_i = df_test_i.set_index('session')\n",
    "        df_candidate = df_candidate.join(df_test_i, on='session', how='left')\n",
    "        df_candidate = df_candidate.join(df_matrice, on=['aid', 'click_predictions'], how='left')\n",
    "        df_candidate = df_candidate.drop('aid', axis=1)\n",
    "        gc.collect()\n",
    "        if i == 0:\n",
    "            df_candidate[col_name] = df_candidate['wgt'].fillna(0)\n",
    "            df_candidate[col_name] = df_candidate[col_name].astype(np.float32)\n",
    "        else:\n",
    "            if normalize:\n",
    "                df_candidate[col_name] = df_candidate[col_name] + (df_candidate['wgt'].fillna(0))/(i+1)\n",
    "            else:\n",
    "                df_candidate[col_name] = df_candidate[col_name] + df_candidate['wgt'].fillna(0)\n",
    "        df_candidate = df_candidate.drop(['wgt'], axis=1)\n",
    "        gc.collect()\n",
    "    return df_candidate\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.173703,
   "end_time": "2023-03-23T12:48:26.720272",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-23T12:48:02.546569",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
