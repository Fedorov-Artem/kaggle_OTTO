# kaggle_OTTO
## Task and solution overview.
This is the code for kaggle competition called "OTTO â€“ Multi-Objective Recommender System". OTTO is Germany's largest online retailer. The task is to predict, which exact next item user is going to click next and which items user is going to add to cart or order before the end of the test period. The competition data is real life new users' sessions on OTTO web site. Test dataset includes one week of users' sessions, truncked at a random point. Oragnizers also provide participants with history of full user's sessions for four weeks, preceeding the test period. But no metainformation is avalable for all the items, that show up in both datasets. Participants only have item id's, that are called AIDs, and there are about 1.8 mln AIDst showing up in the competition data, including both full and truncked user sessions.

From the beginning I have decided to use jupyter notebooks ran on kaggle website to produce the solution. However, this decision turned out to have a number of complications. First of all, kaggle notebooks without GPU support at a time of sompetition had RAM limit of 30 Gb and I had to spend some time, for example, writing code that would merge two dataframes chunk by chunk, as using a simple merge would cause a memory error. Kaggle notebooks with GPU available have RAM limit of just 13 Gb, that made me choose between some features, instead of using all of them. Then, jupiter notebooks are not that usefull when dealing with projects that require a complicated data pipeline. Total number of notebooks used to produce a final solution is 29, and that number does not include a few more notebooks used to test some approaches that turned out to bring no fruit.
