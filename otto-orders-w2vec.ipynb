{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89463283",
   "metadata": {
    "papermill": {
     "duration": 0.004768,
     "end_time": "2023-03-21T12:18:02.381131",
     "exception": false,
     "start_time": "2023-03-21T12:18:02.376363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# W2vec features for orders (cross-validation1 and part_0 of test)\n",
    "\n",
    "In this notebook, the w2vec features for the orders model are built using w2vec model from \"W2vec model for carts and orders\" notebook. There are total 4 w2vec features used by the orders model, two of them are calculated for the last 5 session aids and candidate, another two - for last 20 session aids and candidate. Each group of features is calculated in a single cycle and also using pandarallel library, but anyway this calculation takes time. To decrease the calculation time even further, the task is performed in two notebooks in parallel - this one, and another one with very similar code that calculates the same features for another cross-validation dataset and for another chunk of test dataset.\n",
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb26a77",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:02.391533Z",
     "iopub.status.busy": "2023-03-21T12:18:02.390834Z",
     "iopub.status.idle": "2023-03-21T12:18:03.934073Z",
     "shell.execute_reply": "2023-03-21T12:18:03.932771Z"
    },
    "papermill": {
     "duration": 1.552189,
     "end_time": "2023-03-21T12:18:03.937349",
     "exception": false,
     "start_time": "2023-03-21T12:18:02.385160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc\n",
    "from humanize import naturalsize\n",
    "from gensim.models import Word2Vec\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "# functions and classes common for several notebooks of current project\n",
    "import otto_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c06bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:03.947695Z",
     "iopub.status.busy": "2023-03-21T12:18:03.946694Z",
     "iopub.status.idle": "2023-03-21T12:18:03.952719Z",
     "shell.execute_reply": "2023-03-21T12:18:03.951713Z"
    },
    "papermill": {
     "duration": 0.014316,
     "end_time": "2023-03-21T12:18:03.955461",
     "exception": false,
     "start_time": "2023-03-21T12:18:03.941145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Returns min and max w2vec similarity for the candidate aid and last session aids.\n",
    "def agg_min_max(x, w2v_model):\n",
    "    similarities = []\n",
    "    for item in x.aid:\n",
    "        similarities.append(w2v_model.wv.similarity(item, x.order_predictions))\n",
    "    return [np.min(similarities), np.max(similarities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75e43ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:03.965593Z",
     "iopub.status.busy": "2023-03-21T12:18:03.964799Z",
     "iopub.status.idle": "2023-03-21T12:18:03.971235Z",
     "shell.execute_reply": "2023-03-21T12:18:03.969709Z"
    },
    "papermill": {
     "duration": 0.014976,
     "end_time": "2023-03-21T12:18:03.974206",
     "exception": false,
     "start_time": "2023-03-21T12:18:03.959230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Returns mean and min w2vec similarity for the candidate aid and last session aids.\n",
    "def agg_mean_min(x, w2v_model):\n",
    "    similarities = []\n",
    "    for item in x.aid:\n",
    "        similarities.append(w2v_model.wv.similarity(item, x.order_predictions))\n",
    "    return [np.mean(similarities), np.min(similarities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f18402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:03.984410Z",
     "iopub.status.busy": "2023-03-21T12:18:03.983868Z",
     "iopub.status.idle": "2023-03-21T12:18:03.999367Z",
     "shell.execute_reply": "2023-03-21T12:18:03.997765Z"
    },
    "papermill": {
     "duration": 0.024542,
     "end_time": "2023-03-21T12:18:04.002638",
     "exception": false,
     "start_time": "2023-03-21T12:18:03.978096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import candidates and last N aids for each session, then calculate the w2vec features for them in chunks.\n",
    "def calculate_w2vec_features(train_path, sessions_path, w2v_model, time_delta, n_max, feature_type, feature_name1, feature_name2):\n",
    "    \n",
    "    # Import all the required data and merge it together.\n",
    "    print(feature_type)\n",
    "    df_sessions = pd.read_parquet(sessions_path)\n",
    "    df_sessions = otto_common.filter_by_time_and_n_max(df_sessions, time_delta, n_max)\n",
    "    df_sessions = (df_sessions.groupby('session').agg({'aid': lambda x: x.tolist()}))\n",
    "    df = pd.read_parquet(train_path)\n",
    "    df = pd.merge(df, df_sessions, how='left', on='session')\n",
    "    \n",
    "    # Remove all the columns not relevant to this calculation.\n",
    "    df = df[['order_predictions', 'aid']]\n",
    "    del df_sessions\n",
    "    gc.collect()\n",
    "    \n",
    "    # Prepare data chunks.\n",
    "    i = 0\n",
    "    chunk_size = 10000000\n",
    "    while i < 1000000000:\n",
    "        df_chunk = df.iloc[i:i+chunk_size,:].copy()\n",
    "        \n",
    "        # Calculate the features.\n",
    "        #pandarallel.initialize(nb_workers=4, progress_bar=True)\n",
    "        pandarallel.initialize(nb_workers=4)\n",
    "        if feature_type == 'mean_min':\n",
    "            df_chunk['features']  = df_chunk.parallel_apply(\n",
    "                lambda x: agg_mean_min(x, w2v_model), axis=1)\n",
    "        elif feature_type == 'min_max':\n",
    "            df_chunk['features']  = df_chunk.parallel_apply(\n",
    "                lambda x: agg_min_max(x, w2v_model), axis=1)\n",
    "        else:\n",
    "            print('feature_type_unknown')\n",
    "            \n",
    "        # Format the calculated features.\n",
    "        df_chunk[[feature_name1,feature_name2]] = pd.DataFrame(df_chunk.features.tolist(), index=df_chunk.index)\n",
    "        df_chunk = df_chunk[[feature_name1, feature_name2]]\n",
    "        df_chunk[feature_name1] = df_chunk[feature_name1].astype(np.float32)\n",
    "        df_chunk[feature_name2] = df_chunk[feature_name2].astype(np.float32)\n",
    "        gc.collect()\n",
    "        \n",
    "        # Merge the chunks together.\n",
    "        if i == 0:\n",
    "            df_all = df_chunk.copy()\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df_chunk])\n",
    "        print(i)\n",
    "        i += chunk_size\n",
    "        gc.collect()\n",
    "        if df_chunk.shape[0] < chunk_size:\n",
    "            return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633e0329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:04.012649Z",
     "iopub.status.busy": "2023-03-21T12:18:04.012093Z",
     "iopub.status.idle": "2023-03-21T12:18:04.020948Z",
     "shell.execute_reply": "2023-03-21T12:18:04.019370Z"
    },
    "papermill": {
     "duration": 0.017036,
     "end_time": "2023-03-21T12:18:04.023638",
     "exception": false,
     "start_time": "2023-03-21T12:18:04.006602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define all the parameters for the w2vec features, except for paths, that are different for cross-validation and test datasets.\n",
    "def add_w2vec_data(train_path, sessions_path, w2vec_path):\n",
    "    w2v_model = Word2Vec.load(w2vec_path)\n",
    "    df_w2v_20 = calculate_w2vec_features(train_path, sessions_path, w2v_model, 3 * 60 * 60, 20, 'mean_min', 'w2v_20_mean', 'w2v_20_min')  \n",
    "    gc.collect()\n",
    "    df_w2v_5 = calculate_w2vec_features(train_path, sessions_path, w2v_model, 5 * 24 * 60 * 60, 5, 'min_max', 'w2v_5_min', 'w2v_5_max')\n",
    "    gc.collect()\n",
    "    df_all = pd.read_parquet(train_path)\n",
    "    df_all = pd.concat([df_all, df_w2v_20, df_w2v_5], axis=1)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d305b",
   "metadata": {
    "papermill": {
     "duration": 0.003525,
     "end_time": "2023-03-21T12:18:04.031240",
     "exception": false,
     "start_time": "2023-03-21T12:18:04.027715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## W2vec features for the first cross-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf552d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:18:04.043077Z",
     "iopub.status.busy": "2023-03-21T12:18:04.041729Z",
     "iopub.status.idle": "2023-03-21T12:55:01.804393Z",
     "shell.execute_reply": "2023-03-21T12:55:01.801756Z"
    },
    "papermill": {
     "duration": 2217.774129,
     "end_time": "2023-03-21T12:55:01.809816",
     "exception": false,
     "start_time": "2023-03-21T12:18:04.035687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_min\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "0\n",
      "min_max\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# All the paths and w2vec feature calculation.\n",
    "train_path_cv1 = '/kaggle/input/otto-feature-engineering-orders/cv_features_order.parquet'\n",
    "sessions_path_cv1 = '/kaggle/input/otto-prepare-cv/cv_inputs.parquet'\n",
    "w2vec_path_cv = '/kaggle/input/otto-word2vec-exp/word2vec_cv_exp.wordvectors'\n",
    "\n",
    "df_cv1 = add_w2vec_data(train_path_cv1, sessions_path_cv1, w2vec_path_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a77c636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:55:01.826994Z",
     "iopub.status.busy": "2023-03-21T12:55:01.826470Z",
     "iopub.status.idle": "2023-03-21T12:55:09.400563Z",
     "shell.execute_reply": "2023-03-21T12:55:09.399403Z"
    },
    "papermill": {
     "duration": 7.58912,
     "end_time": "2023-03-21T12:55:09.404096",
     "exception": false,
     "start_time": "2023-03-21T12:55:01.814976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check size and export to file.\n",
    "\n",
    "size = df_cv1.memory_usage(deep='True').sum()\n",
    "print(naturalsize(size))\n",
    "df_cv1.to_parquet('train_features_with_w2v_cv1.parquet')\n",
    "\n",
    "del df_cv1, train_path_cv1, sessions_path_cv1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab008a8c",
   "metadata": {
    "papermill": {
     "duration": 0.107193,
     "end_time": "2023-03-21T12:55:09.517121",
     "exception": false,
     "start_time": "2023-03-21T12:55:09.409928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## W2vec features for Part_0 of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fb8002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T12:55:09.548716Z",
     "iopub.status.busy": "2023-03-21T12:55:09.547195Z",
     "iopub.status.idle": "2023-03-21T15:38:07.134258Z",
     "shell.execute_reply": "2023-03-21T15:38:07.132310Z"
    },
    "papermill": {
     "duration": 9777.606847,
     "end_time": "2023-03-21T15:38:07.138143",
     "exception": false,
     "start_time": "2023-03-21T12:55:09.531296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_min\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "0\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "10000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "20000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "30000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "40000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "50000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "60000000\n",
      "min_max\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "0\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "10000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "20000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "30000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "40000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "50000000\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "60000000\n"
     ]
    }
   ],
   "source": [
    "# All the paths and w2vec feature calculation.\n",
    "train_path_test_0 = '/kaggle/input/otto-feature-engineering-orders/test_features_order_part_0.parquet'\n",
    "sessions_path_test = '/kaggle/input/otto-prepare-cv/test.parquet'\n",
    "w2vec_path_test = '/kaggle/input/otto-word2vec-exp/word2vec_test_exp.wordvectors'\n",
    "\n",
    "df_test_0 = add_w2vec_data(train_path_test_0, sessions_path_test, w2vec_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b8340d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T15:38:07.153256Z",
     "iopub.status.busy": "2023-03-21T15:38:07.152759Z",
     "iopub.status.idle": "2023-03-21T15:38:46.454202Z",
     "shell.execute_reply": "2023-03-21T15:38:46.452697Z"
    },
    "papermill": {
     "duration": 39.313062,
     "end_time": "2023-03-21T15:38:46.457554",
     "exception": false,
     "start_time": "2023-03-21T15:38:07.144492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Check size and export to file.\n",
    "size = df_test_0.memory_usage(deep='True').sum()\n",
    "print(naturalsize(size))\n",
    "df_test_0.to_parquet('train_features_with_w2v_part_0.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12059.123979,
   "end_time": "2023-03-21T15:38:47.915679",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-21T12:17:48.791700",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
